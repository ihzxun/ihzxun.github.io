---
layout: post
title: 基本的ELK日志分析系统搭建
tags: ["ELK"]
---

　　现在我们的应用日志使用传统的文件方式记录，日志文件散落在各个服务器的logs文件夹下．查找监控分析都很不方便，所以需要升级为先进的集中化日志平台．

## 简介
ELK由Elasticsearch、Logstash和Kibana三部分组件组成；
Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。
Logstash是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用
kibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。

![架构图](/static/img／2019/elkjg.jpeg)

##　快速搭建ELK

服务器有限，现在只有一个centos7的服务器，所以都安装在这里．都按照官方文档来就行！

https://www.elastic.co/cn/downloads/logstash

https://www.elastic.co/cn/downloads/elasticsearch

https://www.elastic.co/cn/downloads/kibana

## 用logstash来收集系统性能信息

安装collectd

https://collectd.org/download.shtml

默认配置文件的位置/opt/collectd/etc/collectd.conf ，需要修改其中的network配置

logstash.conf 修改为:
~~~
input {
        udp {
                port => 25826
                codec => collectd {}
                type  => "collectd"
        }
}
output {
       stdout {
                codec   => rubydebug
        }

}
~~~

启动collectd
~~~
/opt/collectd/sbin/collectd
~~~

启动logstash
~~~
./bin/logstash -f config/logstash.conf 
~~~

logstash日志中会出现统计信息
~~~
{
      "collectd_type" => "cpu",
             "plugin" => "cpu",
      "type_instance" => "idle",
    "plugin_instance" => "0",
               "host" => "localhost",
         "@timestamp" => 2019-03-04T03:49:47.681Z,
              "value" => 422072,
           "@version" => "1",
               "type" => "collectd"
}
~~~
## Logstash数据注入到Elasticsearch

logstash.conf 修改为:
~~~
input {
        udp {
                port => 25826
                codec => collectd {}
                type  => "collectd"
        }
}
output {
      elasticsearch {
        hosts => ["192.168.151.148:9200"]
    }
}
~~~


## 程序改造

我们的python程序需要使用＂python-logstash＂通过ＵDP方式把日志发送到logstash服务！

示例：
~~~
import logging
import logstash
import sys

host = '192.168.151.148'

test_logger = logging.getLogger('python-logstash-logger')
test_logger.setLevel(logging.INFO)
test_logger.addHandler(logstash.LogstashHandler(host, 5959, version=1))
# test_logger.addHandler(logstash.TCPLogstashHandler(host, 5959, version=1))

test_logger.error('python-logstash: test logstash error message.')
test_logger.info('python-logstash: test logstash info message.')
test_logger.warning('python-logstash: test logstash warning message.')

# add extra field to logstash message
extra = {
    'test_string': 'python version: ' + repr(sys.version_info),
    'test_boolean': True,
    'test_dict': {'a': 1, 'b': 'c'},
    'test_float': 1.23,
    'test_integer': 123,
    'test_list': [1, 2, '3'],
}
test_logger.info('python-logstash: test extra fields', extra=extra)
~~~

logstash的相关配置文件应改为
~~~
input {
        udp{
               port => 5959 
        }
} 
output {
    elasticsearch {
        index => "pylog-%{+YYYY.MM.dd}"
        hosts => ["http://192.168.151.148:9200"]
    }
}
~~~
## 在kibana中展示数据

需要修改配置文件:
~~~
elasticsearch.hosts: ["http://192.168.151.148:9200"]
~~~


